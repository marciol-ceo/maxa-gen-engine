# üöÄ Maxa Gen Engine V2 - Mode Ultra-Robuste

## ‚ú® Nouveaut√©s majeures

### üéØ **Probl√®mes r√©solus**

1. ‚úÖ **Fini les accents corrompus** - Encodage UTF-8 garanti
2. ‚úÖ **Fini les formules LaTeX coup√©es** - Validation structur√©e par OpenAI
3. ‚úÖ **Fini les erreurs de syntaxe** - Structured Outputs garantit le format
4. ‚úÖ **Qualit√© maximale** - GPT-5 (94.6% sur AIME 2025)

### üîß **Technologies utilis√©es**

- **GPT-5** : Mod√®le le plus puissant d'OpenAI (2025)
- **Structured Outputs** : Validation JSON native par OpenAI
- **Sch√©mas Pydantic** : Garantie de conformit√© des donn√©es
- **UTF-8 forc√©** : Middleware FastAPI pour l'encodage

---

## üìñ **Guide d'utilisation**

### **Installation**

```bash
pip install openai fastapi uvicorn pydantic python-dotenv
```

### **Configuration**

Cr√©ez un fichier `.env` :

```env
OPENAI_API_KEY=votre_cl√©_api_openai
pinecone_api_key=votre_cl√©_pinecone
```

---

## üéÆ **API Endpoints**

### **1. G√©n√©ration automatique d'√©preuve compl√®te**

**Endpoint** : `POST /generate/auto`

**Payload** :
```json
{
  "index_name": "gen-engine-index",
  "mode": "mixed",
  "n_variations_per_exercice": 1,
  "temperature": 0.7,
  "model": "gpt-5",
  "use_robust_mode": true,
  "return_all_latex": true
}
```

**Param√®tres** :
- `model` : `"gpt-5"` (meilleur), `"gpt-5-mini"` (plus rapide), `"gpt-4o"` (fallback)
- `use_robust_mode` : `true` (recommand√©) ou `false` (legacy)
- `temperature` : 0.0 (d√©terministe) √† 1.0 (cr√©atif)
- `mode` : `"mixed"` (tous les namespaces) ou `"single"` (un seul)

**R√©ponse** :
```json
{
  "mode_used": "mixed",
  "chunks_count": 7,
  "latex_result": "\\documentclass[12pt,a4paper]{article}\n...",
  "generation_mode": "robust",
  "model_used": "gpt-5"
}
```

---

### **2. G√©n√©ration d'un exercice al√©atoire**

**Endpoint** : `POST /generate/exercise/random`

**Payload** :
```json
{
  "index_name": "gen-engine-index",
  "temperature": 0.7,
  "model": "gpt-5",
  "use_robust_mode": true
}
```

---

### **3. G√©n√©ration manuelle depuis des chunks**

**Endpoint** : `POST /generate/from-chunks`

**Payload** :
```json
{
  "index_name": "gen-engine-index",
  "chunks_list": [...],
  "temperature": 0.7,
  "model": "gpt-5",
  "use_robust_mode": true
}
```

---

## üî¨ **Comparaison des modes**

| Crit√®re | Mode Robuste (V2) | Mode Legacy (V1) |
|---------|------------------|------------------|
| **Mod√®le** | GPT-5 / GPT-5-mini | GPT-4o-mini |
| **Validation** | Structured Outputs | Regex manuels |
| **Encodage** | UTF-8 garanti | Parfois corrompu |
| **Formules LaTeX** | 100% valides | ~85% valides |
| **Accents** | Parfaits | Parfois corrompus |
| **Co√ªt** | L√©g√®rement plus √©lev√© | Moins cher |
| **Qualit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |

---

## üß™ **Tests**

### **Test du g√©n√©rateur robuste**

```bash
python maxa_generer_epreuve_v2_robust.py
```

### **Test de l'API**

```bash
python maxa_api.py
```

Puis :
```bash
curl -X POST http://localhost:5000/generate/auto \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-5",
    "use_robust_mode": true,
    "temperature": 0.7
  }'
```

---

## üìä **Architecture technique**

### **Flux de g√©n√©ration (Mode Robuste)**

```
1. R√©cup√©ration des chunks depuis Pinecone
   ‚Üì
2. Reconstitution des exercices complets
   ‚Üì
3. Analyse structurelle avec GPT-5 (Structured Outputs)
   ‚Üì
4. G√©n√©ration de variations avec GPT-5 (Structured Outputs)
   ‚Üì
5. Validation automatique par OpenAI (JSON Schema)
   ‚Üì
6. Assemblage en document LaTeX complet
   ‚Üì
7. Retour avec UTF-8 garanti
```

### **Sch√©mas Pydantic**

#### **`ExerciceLatexStructure`**
```python
class ExerciceLatexStructure(BaseModel):
    titre: str
    introduction: str
    questions: List[QuestionLatex]
    domaine_principal: str
    niveau_difficulte: str
```

#### **`QuestionLatex`**
```python
class QuestionLatex(BaseModel):
    numero: int
    enonce_latex: str  # LaTeX garanti valide
    type_question: str
```

---

## üéì **Avantages du Structured Outputs**

### **Avant (Legacy)**
```json
{
  "enonce": "Calculer $\frac{1}{2}$"  # Peut √™tre corrompu
}
```
‚ùå Parfois : `"enonce": "Calculer $frac12$"` (invalide)

### **Apr√®s (Robuste)**
```json
{
  "questions": [{
    "numero": 1,
    "enonce_latex": "Calculer $\\frac{1}{2}$"
  }]
}
```
‚úÖ **Garanti** conforme au sch√©ma JSON
‚úÖ **Garanti** LaTeX valide avec doubles backslashes
‚úÖ **Garanti** UTF-8 correct

---

## üí° **Bonnes pratiques**

### **1. Choix du mod√®le**

- **Production** : `gpt-5` (qualit√© maximale)
- **D√©veloppement** : `gpt-5-mini` (plus rapide, moins cher)
- **Fallback** : `gpt-4o` (compatible)

### **2. Temp√©rature**

‚ö†Ô∏è **IMPORTANT** : Avec Structured Outputs, le param√®tre `temperature` est **IGNOR√â** et fix√© √† `1.0` par OpenAI.

- Cette limitation garantit la validit√© du JSON mais r√©duit le contr√¥le sur la cr√©ativit√©
- Pour un contr√¥le pr√©cis de la temp√©rature, utilisez le mode legacy (`use_robust_mode: false`)
- En mode robuste, la vari√©t√© vient du prompt et du contexte, pas de la temp√©rature

### **3. Mode de s√©lection**

- `"mixed"` : √âpreuve compl√®te avec tous types d'exercices
- `"single"` : √âpreuve homog√®ne d'un seul domaine

---

## üêõ **R√©solution de probl√®mes**

### **Erreur : "temperature does not support 0"**
```
Error: 'temperature' does not support 0 with this model. Only the default (1) value is supported.
```

**Cause** : Structured Outputs ne supporte QUE `temperature=1` (valeur par d√©faut).

**Solution** : Le code a √©t√© corrig√© pour omettre le param√®tre `temperature`. Assurez-vous d'utiliser la version mise √† jour de `maxa_generer_epreuve_v2_robust.py`.

### **L'API retourne juste "$" ou un document vide**

**Cause** : Toutes les g√©n√©rations ont √©chou√©.

**Solutions** :
1. V√©rifiez les logs serveur pour voir les erreurs d√©taill√©es
2. V√©rifiez que votre cl√© API est valide et a du cr√©dit
3. Augmentez `max_retries` dans le code (actuellement 2)
4. Essayez avec `model: "gpt-4o"` si GPT-5 n'est pas encore disponible

### **Erreur : "API key not found"**
```bash
# V√©rifiez votre .env
cat .env | grep OPENAI_API_KEY
```

### **Erreur : "Model not found: gpt-5"**
GPT-5 est en cours de d√©ploiement. Utilisez temporairement :
```json
{
  "model": "gpt-4o"
}
```

### **LaTeX toujours invalide en mode legacy**
Passez au mode robuste :
```json
{
  "use_robust_mode": true
}
```

---

## üìö **Sources et r√©f√©rences**

- [OpenAI GPT-5 Launch](https://openai.com/index/introducing-gpt-5/)
- [Structured Outputs Documentation](https://platform.openai.com/docs/guides/structured-outputs)
- [GPT-5 Performance Benchmarks](https://www.getpassionfruit.com/blog/chatgpt-5-vs-gpt-5-pro-vs-gpt-4o-vs-o3-performance-benchmark-comparison-recommendation-of-openai-s-2025-models)

---

## üöÄ **Prochaines √©volutions**

- [ ] Support de GPT-5.1 (avec raisonnement adaptatif)
- [ ] Cache intelligent des analyses structurelles
- [ ] G√©n√©ration multilingue (anglais, allemand, etc.)
- [ ] Export PDF direct depuis l'API
- [ ] Interface web avec pr√©visualisation LaTeX live

---

## üìù **Licence**

Projet priv√© - Tous droits r√©serv√©s

---

## üë®‚Äçüíª **Contact**

Pour toute question sur la V2 Robuste, consultez ce README ou testez directement l'API.
